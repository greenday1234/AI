{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09123ff9",
   "metadata": {},
   "source": [
    "# library importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33afef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sklearn\n",
    "import warnings\n",
    "import random\n",
    "from keras import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from unicodedata import normalize\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Dense, TimeDistributed, Dropout, Bidirectional, GRU, BatchNormalization, Activation, LeakyReLU, LSTM, Flatten, RepeatVector, Permute, Multiply, Conv2D, MaxPooling2D\n",
    "warnings.filterwarnings('ignore', module='sklearn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834be73c",
   "metadata": {},
   "source": [
    "# Ready for Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17d8eb9",
   "metadata": {},
   "source": [
    "## Data Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05e549ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오디오 데이터\n",
    "DATA_DIR_TRAIN = '/Users/ichanhui/Desktop/TranslationAudio/train/'\n",
    "DATA_DIR_TEST = '/Users/ichanhui/Desktop/TranslationAudio/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2d04ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sr :  16000\n",
      "wav shape :  (60696,)\n",
      "length :  3.7935 secs\n"
     ]
    }
   ],
   "source": [
    "# Example : scream 폴더의 음성 파일 접근\n",
    "wav, sr = librosa.load(DATA_DIR_TRAIN + 'scream/4.wav', sr=16000)\n",
    "print('sr : ', sr)\n",
    "print('wav shape : ', wav.shape)\n",
    "print('length : ', wav.shape[0]/float(sr), 'secs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d0d04d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<matplotlib.lines.Line2D object at 0x7fa2fe1bbcd0>]\n",
      "[<matplotlib.lines.Line2D object at 0x7fa2fe1bb970>]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAmUElEQVR4nO3deXxU1f3/8dcnCWEXRBDZNKC4ICpqxAV3RVm01K/WSqtVa8vX/rRf22+txaqte6m2X5dqtbhUa1XcKxVcAFcUkYCAILLIIlshgCA7JPn8/phLnISZZJK5k5nJvJ+PRx6599xz73wOZOYz99x7zzF3R0REcldeugMQEZH0UiIQEclxSgQiIjlOiUBEJMcpEYiI5LiCdAdQH+3bt/eioqJ0hyEiklWmTp26xt07VC/PykRQVFRESUlJusMQEckqZrYkVrm6hkREcpwSgYhIjlMiEBHJcUoEIiI5LpREYGaPm9lqM5sVZ7uZ2f1mtsDMZprZUVHbBpjZ3GDb8DDiERGRxIV1RvAEMKCG7QOBnsHPMOAhADPLBx4MtvcChppZr5BiEhGRBISSCNz9fWBdDVWGAP/wiI+BtmbWCegLLHD3he6+AxgV1BURkQbSUNcIugBLo9aXBWXxyndjZsPMrMTMSkpLS1MWqNRs9ooNfPrV1+kOQ0RC1FCJwGKUeQ3luxe6j3T3Yncv7tBhtwfjpIEMvn8i5/31o3SHISIhaqgni5cB3aLWuwIrgMI45SIi0kAa6oxgNPCj4O6h44AN7r4SmAL0NLPuZlYIXBTUFRGRBhLKGYGZPQucCrQ3s2XA74EmAO7+MDAWGAQsALYAlwfbyszsauBNIB943N1nhxGTiIgkJpRE4O5Da9nuwFVxto0lkihERCQN9GSxiEiOUyKQeimviHlzl4hkISUCqZcV67emOwQRCYkSgYhIjlMikKTsLK+g//+9xztzV6c7FBGpJyUCScrqjduZv3oTN7z8WbpDEZF6UiIQEclxSgSSsMjjILHpJiKR7KVEIKH4zzfb0h2CiNSTEoEkrIYTAhHJYkoEkpRY44iLSHZpqGGopRGofkIwY+l6Xpq2LC2xiEh4lAgkYZt3lFVZH/Lgh2mKRETCpK4hSdgdr81JdwgikgJKBJKw50qW1l5JRLKOEoGISI4LJRGY2QAzm2tmC8xseIztvzaz6cHPLDMrN7N2wbbFZvZZsK0kjHhERCRxSV8sNrN84EGgP5FJ6qeY2Wh3/3xXHXe/G7g7qH8u8Et3Xxd1mNPcfU2ysYiISN2FcUbQF1jg7gvdfQcwChhSQ/2hwLMhvK6IiIQgjETQBYi+irgsKNuNmbUABgAvRRU78JaZTTWzYfFexMyGmVmJmZWUlpaGELaIiEA4iSDWw6XxBiM4F/iwWrdQP3c/ChgIXGVmJ8fa0d1Hunuxuxd36NAhuYhFRKRSGIlgGdAtar0rsCJO3Yuo1i3k7iuC36uBV4h0NUmG21Feke4QRCQkYSSCKUBPM+tuZoVEPuxHV69kZm2AU4BXo8pamlnrXcvAWcCsEGKSFHt84qJ0hyAiIUn6riF3LzOzq4E3gXzgcXefbWZXBtsfDqqeB7zl7pujdu8IvGJmu2J5xt3fSDYmSb2tO8rTHYKIhCSUsYbcfSwwtlrZw9XWnwCeqFa2EDgijBhERKR+9GSx1MvLny5PdwgiEhIlAhGRHKdEICKS45QIRERynBKBiEiOUyIQEclxSgQiIjlOiUBEJMcpEYiI5DglAhGRHKdEICKS45QIRERynBKBpMyGrTu55LHJrN64Ld2hiEgNlAgkZf4wdg4fzF9D3zsmpDsUEamBEoGkzCeL1tVeSUTSTolAEjL8pZnpDkFEUiSURGBmA8xsrpktMLPhMbafamYbzGx68PO7RPeVzDBqytI677OzQvMai2SDpGcoM7N84EGgP5GJ7KeY2Wh3/7xa1Q/c/Zx67itZaNtOJQKRbBDGGUFfYIG7L3T3HcAoYEgD7CsZrnTj9nSHICIJCCMRdAGi+w2WBWXVHW9mM8zsdTM7tI77YmbDzKzEzEpKS0tDCFsS4e78+Ikp6Q5DRFIojERgMcq82vo0YD93PwL4C/CvOuwbKXQf6e7F7l7coUOH+sYqdfT1lp28/cXqdIchIikURiJYBnSLWu8KrIiu4O7fuPumYHks0MTM2ieyr6TXX96eH8pxtuwoC+U4IhK+MBLBFKCnmXU3s0LgImB0dAUz28fMLFjuG7zu2kT2lfTatC2cD/Ala7dULq/bvAP3mCd+IpIGSScCdy8DrgbeBOYAz7v7bDO70syuDKpdAMwysxnA/cBFHhFz32Rjksyz63N/wepNHHXbOB6buCi9AYlIpaRvH4XK7p6x1coejlp+AHgg0X0lc5SH9M29IjjO+DmrALh9zBx+clKPUI4tIskJJRFI4/XytOX12m/bzvIq63NWfkOb5k0Y8foXYYQlIiHSEBMSuuXrt3LwTW9UKfv1izOZvWJDmiISkZooEUjo+o14O2b5lf+c1sCRiEgilAhERHKcEoGISI5TIpC4Nm7bme4QRKQBKBFIXPNWbUrp8Rev2ZzS44tIYpQIJG1uHzMn3SGICEoEkkZlmrhGJCMoEUjavDu3lHfnamRTkXRTIpAapH5guMv+rrkORNJNiUDievCdL9Mdgog0ACUCias+E9K8Or1+YxOJSPooEUiorhk1Pd0hZJxtO8uZtVzjLEnmUiKQ0BQNH1Ov/Vas3xpyJPG5O/eOn7fb6KjJ2LS9jOEvzYz7AN7BN73BOX+ZyOpvtgHwnw3bQn39XYqGj6n3/4HkNiUCSbsTRrxNzxuqTkmxbWc5r05fHvpMZiPfX8i94+fvNjpqMh77YBGjpizlsJvf4rQ/vcuLU5fFrPfB/DUAHPeHCVz9TOoG4Nuyo4zl67dSUaFZ4CQxoSQCMxtgZnPNbIGZDY+x/YdmNjP4+cjMjojattjMPjOz6WZWEkY8kn12ljvlUR9cd4yZwzWjpjNp4dpQjj9x/hoWr9nMuM9X1Vp3w9adLKrDU8/3jJ9XubxozWaufWFG5frXm3dULv/qhRl8HLRn/JzU3Tb71KQl9BvxNoPu/0BTgkpCkk4EZpYPPAgMBHoBQ82sV7Vqi4BT3P1w4DZgZLXtp7l7H3cvTjYeyV5PTVr87fLHS4Bw5kz+bNkGLn5sMqf+6V1KlnxdWf4/z37K81OW4u6s37KDpyYtxt0Z8sBETvvTu7sd4/bXPmftpu3cOXYOB974OmXlFSz7egs1OfK2cVXWLxr5cdLtibZha6Q7KvoD/w/B5D9f/Gcj780rDfX1pHEK44ygL7DA3Re6+w5gFDAkuoK7f+Tuu96BHwNdQ3hdaWRu/vfnALwT8kNm5z4wMWb56BkruO6lmXwwfw19bh3HTa/Opvv1Y1m8NvLhPmflN5V1z/vrhzw6cRFH3z6eke8vZEdZBZ8t38D6LakdmG/VN9soGj6GKYvX7bZt0pdrOeKWt3hn7mq2xrnmEOs5jdKN2yuvV4hAOImgC7A0an1ZUBbPFcDrUesOvGVmU81sWLydzGyYmZWYWUlpqb7lNFbPTfmKy6M+vB58Z0Hcutt2lvNCydKkuz9enb4iZvnA+z7gxanL2FleQVmM/vYla7dwzl9iJ5k/vTmXqUt2//Cuq11dSf+YFDlD2rKjjKnBWc20ryK/7xk3jy07Er/4fMwd4+l75wSKho9hZ7mG+ZBwEoHFKIv5zjSz04gkgt9EFfdz96OIdC1dZWYnx9rX3Ue6e7G7F3fo0CHZmCVD/ealz6qsz1gW/7bLu96Yy69fnMnoGbE/yAHKEvige2la7Iu7ANe+MIMH3o6djCpqSEAPvLOA8x+aVOPrrkrgW/mm7ZGusX/PWME/P17CkAc+5PyHPqJ04/bKuGYu28APHonf5fSbF2cCsGD1Rl6u1tbzH/qo1hik8Qtj8vplQLeo9a7Abu9MMzsceBQY6O6VVwDdfUXwe7WZvUKkq+n9EOKSRsjd+efkr/hun848/uEiIPLswpA+XZi3aiPNCvI5+e53ABhw6D68Mfs/Sb/mmk3bY5b/7/MzYpYn6tg7J7B4xOCYrzfy/YVcd/ZBPPrBosryG/81q3L5q3Wbq3QH1TRk+HMlS3muZGnMbTNrSLSSO8JIBFOAnmbWHVgOXAT8ILqCme0LvAxc4u7zospbAnnuvjFYPgu4NYSYpBF5evIS+h/Skb33aMaN/5rF05O/2u2bLcBZ91T9/hBGEgAqu2JS4a/vLuCKE7vTtCC/suzOMXN4+dPl5OdZ3LuXajvbqIvnS5ZyYfG33+V2lFVQkGfk5cU62ZfGyMK4vczMBgH3AvnA4+5+h5ldCeDuD5vZo8D5wJJglzJ3LzazHsArQVkB8Iy731Hb6xUXF3tJie40TbVMezjp3CM68+843UDv/fpUTrn73YYNKES3fbc3nds0Y8TrXzB/dWonBIpl4m9Oo+ueLXh52rLKM50PrjuNbu1aVKlXunE7n371NSf17MBD7y6geWEBPzt1/waPV+rHzKbGujszlETQ0JQIGkamJQJJrb9fdgyXP1H1LqMJvzqFsnLn7HvfZ8oNZ3LMHeN32y9W95ZkJiUCqTMlAknEH/7rMIb23TfdYUgC4iUCDTEhIkm5/uXPaq8kGU2JQESS9u8ZKzToXRZTIhCRpP382U8rl5+evKSGmpKJlAhEJFQ3vDKr9kqSUZQIJKa6jL4pUt1Z97zHPePm1V5RMoISgcQ0PoHhmkXimbdqE/dNmM/p1UZx3WXlhq2s3xIZotvdNeZRmikRSEymh0olBAvXbKZo+BhmLd/Aus07+DQYKO/4P7xNn1vHUTR8DL995TN63vA6pRtjD+Wxy7ad5RQNH8NrM+OPLSX1E8YQEyIiNYo3SivAs59ExkE65o7x/Ol7R1RO7FP9QbUXgvGSrn7mU845vHOKIs1NOiMQkYwRPbtb0fAxnH3P+0xeuJbN28tYGHXdqvfv32SxrmOFRmcEIpKx5q7ayPdjzOq2aXsZP3t6Gq9fc1Iaomp8dEYgIlkpegY5SY4SgcRkuloskjOUCCQmpQGR3KFEIDHphECk4ZVXODOXrW/w1835RDB7xQa27CiLuW3qknWVk4fXxc7yCtZs2s70petjbt+8PfbrJev6l2fy/JTYUxICTF64lhlL1zMueFhs645y+o14mw/ml6YkHpFcN+7zVWzaXsY7c1fzxqzaZ8x78J0FfOeBDylZvI6KioabIiCUu4bMbABwH5EZyh519xHVtluwfRCwBbjM3aclsm8qbdtZzuD7I/c3n3N4J4r325N+B7SnR4dW3D9hPvdNmF9Z98Lirkz7aj1PXH4Mf3xjLmf16sjXW3bwo+OLWLF+K4UFeezZopCyigoOuvGNyv3m3zGQCx6eRPMmeZRu3M6XpZFb3nru3YqeHVtxxYndGf7SZ3yzbSeThp/B2s07cHcWlG7iB49M5t1rT2W/vSKzRN03YT73jo/EdN2Ag9ijWRPatSzk/XmlfPjlGpau28qznyzlupcik5UX77cnTmSqxd+d04tbX/u8Mq7FIwbzZekmlq/fyiWPfVKl/L15pdzy72/rimSqeas2cmDH1ukOYzdDR37MpBhfIktuPJO9WhYyesYKrhk1HYCRlxzNNaOm89QVfSu/lF3w8CTOOHhviova8cc3vmDYyT2Y9OVaendpw+3f7U1+yNOIJj0xjZnlA/OA/kQmsp8CDHX3z6PqDAJ+TiQRHAvc5+7HJrJvLMlMTDP9rgH02RKZ77Vo29OoN1wk+/367IO46rQDKK9w8vMMd0/bDQ/uTvfrx6bs+H+75GjOPnSfeu0bb2KaMM4I+gIL3H1h8EKjgCFA9If5EOAfHsk6H5tZWzPrBBQlsG9oJj0xnOO3fDvp9+G2kJmu+VZFst3db87l7jfnpjuMBrG9LPxxmcK4RtAFiO6YXhaUJVInkX0BMLNhZlZiZiWlpfXr0z5+8UNV1kc3valexxERSZdzD+8U+jHDOCOIdf5Vvb8pXp1E9o0Uuo8ERkKka6guAVa6eQPc3KZy9cXyk+t1GBHJHt87uisnHLAXrZs2oVmTfNq1LARgW1k5vTrtQWF+Huu37qS8wmnWJI8m+Xl8vWUHzQryaVKQx5btZbRsWkBBvuEOBXlGWdAFlW+GE7lBJM+MTdvL+MVz03l/XupuwEhFl1cYiWAZ0C1qvStQfXjAeHUKE9g3VJt/tYTZ4/9B3xk3UdJ+CKyMlPc7YC8O7dyG4v32ZI/mTXj7i9WMfH/hbvs/dUVfHpu4iDbNm7BfuxYctM8ejJ+zijbNm/DER4sr63Vp25zl67fSojCfLTvKE46vbYsmrN+ys3K9f6+OlXf5iEhV/31yD64fdEjSx9mVHHbp1KZ55XKrprt/TBbkV13Pz4sUtCso5InLjqHHb8O5RnBWr468FfX+/9mpqenKDuNicQGRC75nAMuJXPD9gbvPjqozGLiaby8W3+/ufRPZN5ZkLhbXxYatO5m9fAOHd2uLETlVifVHUZtN28uYMGcVE+as5uenH0DHNs14fOIizj50H5o1yeeXz03n8K5tuHVI78p93pm7mh7tW7LfXi0BKFm8jgP2bkWzJvm8MHUZFx+7b+U3g1nLN3DTq7N49EfFPPLBIuas/IbObZvRp1tbLizuxqvTV9C0II/ObZvz6MRF/HvGCubcOoDmhZE/3m07yynIM/LM2F5WwddbdvCLUdP5ZPG6pP8NRVKp+gilmeLN2f9hYelmzjhkb7q3b8kni9bxw0cn88APjqwcOdXdmb50PUu/3kphfh6FBcby9dvIM/joy7X84oye9OzYmu1l5WzbWUGb5k2SjivexeKkE0Fw8EHAvURuAX3c3e8wsysB3P3h4PbRB4ABRG4fvdzdS+LtW9vrNVQiyGUX/m0SnyxSIpDMlqmJIFOl8q4h3H0sMLZa2cNRyw5clei+kn66qVYkd+T8k8USm4aYEMkdSgQSU54ygUjOUCKQmJQHJNOFPMpCTlMikJhMVwkkww08LPwHq3KVEoHEpDMCyXR3X3B4ukNoNJQIJCbNUCaZ7InLj6FFoaZcD4sSgcTUNoSHV0TCtFfU07+nHrR3GiNpfJQIJKb/7X9gukMQqWLqTf3THUKjpXMrialZk/zaK4nUw03n9OLC4q4U5OXRvDAfd+eRDxbSbc8WDDysE0XDxwBw65BD6dCqaZWLwp/fejYFefr+GjYlAslKA3vvw+sJTP0n6delbXNeueoE9mxRyIr1WyvHz9rFzBh28reDqU298UzMbLeB4ABdF0gR/atK1ll45yDy8qzym+N9F/Vh79bNGPrIx2mOTGL5cPjplcvVk0Ase7VqmspwJAYlAokpk28aygueJJp1y9k8PnER5xzemfw8Y8oNZ7JozWYu/NukWo4gqXbekV24cfAhFOSrGycb6H9JYsrUPPCXoUdWLrdqWsD/nNGzciLvDq2b0rd7O+67qE+aostus245mw+uO41rzzqQ3ww4OOH9nvxxXw7tvEeVsnu+34e9WjUNZehkST2dEUhMe2TQG/j35/biwuJutExwLoghfbqwfstOBh3WicKCPI645a0UR5j9Zt1yNq2aFtCqaQFXn94TgO7tWzDtq/VMXrSOGUvX77ZP9BDQpxzYgU3by7h33DyuPfughgpbQqJEIDFlwl1Dzw07jmN77FWvfS89oSjp129ZmM9dFxzBVc9MS/pYmeypK/rGnHBpQO9ODOhddRiHXddlYmnVtIAbz+kVenySeuoakozRuU0z7vn+EZXrB3ZsnbLXevanx/G3S44G4JmfHhuzzp3/dRjH9WiXshgyxUk9OyRcd/GIwcy8+SwW3DEwhRFJQ0vqjMDM2gHPAUXAYuBCd/+6Wp1uwD+AfYAKYKS73xdsuxn4KbBrpuffBhPVSA668JhunHdkVwYfFrn4mx/S8JJ/GXokP3/20yplx+8fOdOYd/tACgvyOGH/vfjoy7VV6lS46w6WGPZoljndhhKOZM8IhgMT3L0nMCFYr64M+JW7HwIcB1xlZtHnj/e4e5/gR0kgg7z361Mb9PWuPCVyL3lhQV5oSQDg3CM6c+PgQ/j9ub2YdlN/ptxwZuW2woLIW+D0gyNDFjz6o2Ievywyk9/hXdsCcEinqhdCd3n32lP58s5BNb72mP85kYG990m2CSIplWwiGAI8GSw/CXy3egV3X+nu04LljcAcoEuSrysNIJF7vsOUyusSPzmpB5f36067loV0aL37t/wf9+vOMz85ljN7deT0gzuyeMRg9u/QCoDXrzkp5jGL2rckP8+qdGdVd2jnNjx08dHhNCIFjt5vz3SHIBkg2UTQ0d1XQuQDH6hxJCgzKwKOBCZHFV9tZjPN7HEzi/tXaWbDzKzEzEpKS0vjVZMs9exPj0vr6+flGScc0D7u9prOUM47siuLRwzmrV+eXKU8uh997u0Dkg8yBX55psaUkgQSgZmNN7NZMX6G1OWFzKwV8BLwC3f/Jih+CNgf6AOsBP4cb393H+nuxe5e3KFD4he3JDscvE/qLgyHYcEdA7nzvMNqrFP94nb0w1RNC3Y/24k1hEJDO7Fn/OQnuaPWRODuZ7p77xg/rwKrzKwTQPB7daxjmFkTIkngaXd/OerYq9y93N0rgEeAvmE0StJjzxb1u4i4eMRg9syAD8WamBnnH51cj+ZPTuwOwODDOvHaz09k2k39+cmJ3Zl2U39m3XI2Zx7SMYxQa/RwVDdVpidfaTjJdg2NBi4Nli8FXq1ewSIznDwGzHH3/6u2Lfom5fOAWUnGI2n07rWnpTuElIr+Vv/ClcfHrPP3y44B4IPrdv+3uG7Awdx0Ti/uu6gPvbu0AeDGc3rRrmUhrZoW8OilxXxywxmc1avmhPD8f8d+7UQM6L0Pk397Bpcevx8v/eyEeh9HGpdkHygbATxvZlcAXwHfAzCzzsCj7j4I6AdcAnxmZtOD/XbdJnqXmfUBnMjtp/+dZDySRvn5mTowRXjm3T6QCve4F7ZPO3jvKk/cRissyOOK4Kwgnr1bN2Pkj4or12M9wNW3eztOObAD782LXCv7Vf8D+fO4eYk2gY57NOOWIb0Tri+NX1KJwN3XAmfEKF8BDAqWJxJn6Bp3vySZ15fMEuvp1NoM6dM5BZGkzq7bTdPtrz88irvfnMuO8gp+fkbPKongtiGHcsnxRazdtJ2jbx9fWT74cE32LrFpiAlJqz9/L/6tlwJn9erIW5+vqly/fmBkMLiWTQu4+TuHVpb/66p+/PmtuZzcswMXH7cfEBnO+cQD2jNxwRoAbomqLxJNiUBqZAbuqTu+himu2dWnH8Bbn6/inu8fwXlHdo1br0+3tjx1xe5DZTx6aTEfL1zLoZ3b0F5PSUscSgRSo3wzylKUCY4p0sNMtTm8a1um3dS/3reaNmuSr4nepVb6OiY1qusENdXHpa/52I3/4nIYMuF5A2nclAikRnX9sK5LdaUBkcygRCA1yq9jIrjr/MQv/g7tu29dwxGRFFAikBrVtfemVx26hpo10Z+fSCbQO1Fq9LsUzjiVp2sEIhlBiUBqdGjnNik7dmtNcCKSEZQIpEb1+dLeJsGJ78OcfEZE6k+JQGp0UD1GqDwnwaEM9ByBSGZQIpAaNanHk7+/Ozex6wp6jkAkMygRSOiaFuRz2QlF6Q5DRBKkRCAp0bwwdfMPi0i4lAgkJbbvrEh3CCKSICUCSYkLjq46UuY/Y4yMKSKZIalEYGbtzGycmc0Pfse8DcTMFpvZZ2Y23cxK6rq/ZJ9ObZpVWT+uR7s0RSIitUn2jGA4MMHdewITgvV4TnP3Pu5eHFVWl/0lTSb86pSkj5HCKQ1EJEnJJoIhwJPB8pPAdxt4f2kA+3doVed99MEvkj2STQQd3X0lQPA73gwYDrxlZlPNbFg99sfMhplZiZmVlJaWJhm2iIjsUusMZWY2HtgnxqYb6vA6/dx9hZntDYwzsy/c/f067I+7jwRGAhQXF+sLZ4Zr3UyT34lki1rfre5+ZrxtZrbKzDq5+0oz6wSsjnOMFcHv1Wb2CtAXeB9IaH/JPrU9kfzwxUc1UCQiUptku4ZGA5cGy5cCr1avYGYtzaz1rmXgLGBWovtL4xF9S+mA3omNRyQiqZdsIhgB9Dez+UD/YB0z62xmY4M6HYGJZjYD+AQY4+5v1LS/NA7Nm3z7dLE7NC3QYysimSipjlx3XwucEaN8BTAoWF4IxJy/MN7+0ji0b13I0nVb0x2GiNRCX9EkZQap+0ckKygRSOpolGmRrKBEICKS45QIJGU6t2leuZxn0KMeTyiLSOopEUjK/PDYfSuXC/Lz+HG/Ii4s7sq0m/qnMSoRqU6Pf0rK5FWbitLMuOuCmDeQiUga6YxA6uWofdumOwQRCYkSgSTktiGHVln/wbH7MfXGMym5Me4IJCKSJZQIJCEtm+7ei7hXq6YU5MW/R9R0+6hIVlAikKRYDQ8LmDKBSFZQIpCEVP9Md9dI4CKNhRKBJOS4HnvVe9/2rQpDjEREwqbbRyUhnaIeDoOoqShr6f354rYBulYgkuGUCKR+EuwZahY1FLWIZCZ1DUm9VATXCFoW6oNeJNspEUhSCmqZklJEMl9S72Iza2dm48xsfvB7zxh1DjKz6VE/35jZL4JtN5vZ8qhtg5KJRxqO7hkSaTyS/To3HJjg7j2BCcF6Fe4+1937uHsf4GhgC/BKVJV7dm1397HV95fMpLtHRRqPZBPBEODJYPlJ4Lu11D8D+NLdlyT5uiIiEpJkE0FHd18JEPzeu5b6FwHPViu72sxmmtnjsbqWJDO5OodEGo1aE4GZjTezWTF+htTlhcysEPgO8EJU8UPA/kAfYCXw5xr2H2ZmJWZWUlpaWpeXlhRQ15BI41HrcwTuHnd4STNbZWad3H2lmXUCVtdwqIHANHdfFXXsymUzewR4rYY4RgIjAYqLi/UxlGaFultIpNFI9t08Grg0WL4UeLWGukOp1i0UJI9dzgNmJRmPiIjUUbKJYATQ38zmA/2Ddcyss5lV3gFkZi2C7S9X2/8uM/vMzGYCpwG/TDIeaSC6RiDSeCQ1xIS7ryVyJ1D18hXAoKj1LcBuo5a5+yXJvL6IiCRPHb1SL7pYLNJ4KBFIvbRqpvEKRRoLJQKpl8GHdaq9kohkBX2tk3qJnobyz987ggM7tk5jNCKSDCUCSdr5R3dNdwgikgR1DYmI5DglAhGRHKdEICKS45QIRERynBKBiEiOUyKQhJ3Us326QxCRFFAikIQ1LdCfi0hjpHe2iEiOUyKQhF3er3u6QxCRFFAikIT1O0DXCEQaIyUCEZEcl1QiMLPvmdlsM6sws+Ia6g0ws7lmtsDMhkeVtzOzcWY2P/i9ZzLxiIhI3SV7RjAL+C/g/XgVzCwfeJDI5PW9gKFm1ivYPByY4O49gQnBuoiINKBkp6qcA1WHJI6hL7DA3RcGdUcBQ4DPg9+nBvWeBN4FfpNMTJJaD198NE3ya/z/FpEs0xDDUHcBlkatLwOODZY7uvtKAHdfaWZ7N0A8koQBvfdJdwgiErJaE4GZjQdivftvcPdXE3iNWF8f6zzjrZkNA4YB7LvvvnXdXURE4qg1Ebj7mUm+xjKgW9R6V2BFsLzKzDoFZwOdgNU1xDESGAlQXFysqdNFRELSELePTgF6mll3MysELgJGB9tGA5cGy5cCiZxhiIhIiJK9ffQ8M1sGHA+MMbM3g/LOZjYWwN3LgKuBN4E5wPPuPjs4xAigv5nNB/oH6yIi0oDMPft6WYqLi72kpCTdYYiIZBUzm+ruuz3zpSeLRURynBKBiEiOUyIQEclxWXmNwMxKgSX13L09sCbEcNJF7cg8jaUtakdmCbMd+7l7h+qFWZkIkmFmJbEulmQbtSPzNJa2qB2ZpSHaoa4hEZEcp0QgIpLjcjERjEx3ACFROzJPY2mL2pFZUt6OnLtGICIiVeXiGYGIiERRIhARyXE5lQjizZ2cTmb2uJmtNrNZUWVx53I2s+uD+Oea2dlR5Ueb2WfBtvstmDbOzJqa2XNB+WQzK0pBG7qZ2TtmNieYw/qaLG1HMzP7xMxmBO24JRvbERVDvpl9amavZXk7FgcxTDezkmxti5m1NbMXzeyL4L1yfMa0w91z4gfIB74EegCFwAygVwbEdTJwFDArquwuYHiwPBz4Y7DcK4i7KdA9aE9+sO0TIqPAGvA6MDAo/3/Aw8HyRcBzKWhDJ+CoYLk1MC+INdvaYUCrYLkJMBk4LtvaEdWe/wWeAV7Lxr+rqHYsBtpXK8u6thCZjvcnwXIh0DZT2pGS/7hM/An+4d6MWr8euD7dcQWxFFE1EcwFOgXLnYC5sWImMrT38UGdL6LKhwJ/i64TLBcQeULRUtyeV4kMK5617QBaANOITKuade0gMgHUBOB0vk0EWdeO4PiL2T0RZFVbgD2ARdWPmyntyKWuoVhzJ3dJUyy1qTKXM7BrLud4begSLFcvr7KPR+aG2ADslarAg9PRI4l8m866dgTdKdOJzJY3zt2zsh3AvcB1QEVUWTa2AyJT275lZlMtMmUtZF9begClwN+D7rpHzaxlprQjlxJBKHMnp1m8NtTUtgZrt5m1Al4CfuHu39RUNU5MaW+Hu5e7ex8i36j7mlnvGqpnZDvM7BxgtbtPTXSXGGVpb0eUfu5+FDAQuMrMTq6hbqa2pYBIF/BD7n4ksJlIV1A8DdqOXEoENc2dnGlWWWQOZ6zqXM7x2rAsWK5eXmUfMysA2gDrwg7YzJoQSQJPu/vL2dqOXdx9PfAuMIDsa0c/4DtmthgYBZxuZv/MwnYA4O4rgt+rgVeAvlnYlmXAsuAME+BFIokhI9qRS4mgprmTM028uZxHAxcFdwd0B3oCnwSnlBvN7LjgDoIfVdtn17EuAN72oBMxLMFrPgbMcff/y+J2dDCztsFyc+BM4Itsa4e7X+/uXd29iMjf+dvufnG2tQPAzFqaWetdy8BZwKxsa4u7/wdYamYHBUVnAJ9nTDtScXEnU3+AQUTuaPkSuCHd8QQxPQusBHYSyehXEOnXmwDMD363i6p/QxD/XIK7BYLyYiJvkC+BB/j2qfFmwAvAAiJ3G/RIQRtOJHIKOhOYHvwMysJ2HA58GrRjFvC7oDyr2lGtTafy7cXirGsHkb71GcHP7F3v2yxtSx+gJPj7+hewZ6a0Q0NMiIjkuFzqGhIRkRiUCEREcpwSgYhIjlMiEBHJcUoEIiI5TolARCTHKRGIiOS4/w9MmmYCcRmP2wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# raw wave\n",
    "print(plt.plot(wav))\n",
    "print(plt.plot(wav[0:500]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec4b2ab",
   "metadata": {},
   "source": [
    "## Train Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6cb4524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set List, include (raw data, mfcc data, y data)\n",
    "train_dataset = []\n",
    "test_dataset = []\n",
    "\n",
    "dataset0 = [] # 비명소리\n",
    "dataset1 = [] # 일반소리\n",
    "\n",
    "# split each set into raw data, mfcc data, and y data\n",
    "train_x = []\n",
    "train_mfccs = []\n",
    "train_y = []\n",
    "\n",
    "test_x = []\n",
    "test_mfccs = []\n",
    "test_y = []\n",
    "\n",
    "# 모든 음성파일의 길이가 같도록 후위에 padding 처리\n",
    "pad1d = lambda a, i: a[0: i] if a.shape[0] > i else np.hstack((a, np.zeros(i-a.shape[0])))\n",
    "pad2d = lambda a, i: a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i-a.shape[1]))))\n",
    "\n",
    "frame_length = 0.025\n",
    "frame_stride = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa1f1a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 16\n"
     ]
    }
   ],
   "source": [
    "input_nfft = int(round(sr*frame_length))\n",
    "input_stride = int(round(sr*frame_stride))\n",
    "print(input_nfft, input_stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a81099b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ichanhui/opt/anaconda3/lib/python3.9/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=0\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# train data scream 을 넣는다.\n",
    "for filename in os.listdir(DATA_DIR_TRAIN + \"scream/\"):\n",
    "    filename = normalize('NFC', filename) # 'ㅇㅡㅁ.wav' -> '음.wav'\n",
    "    try:\n",
    "        if '.wav' not in filename:\n",
    "            continue\n",
    "        \n",
    "        wav, sr = librosa.load(DATA_DIR_TRAIN + \"scream/\" + filename, sr=16000)\n",
    "        \n",
    "        mfcc = librosa.feature.mfcc(y=wav, sr=sr)\n",
    "        #mfcc = sklearn.processing.scale(mfcc, axis=1)\n",
    "        padded_mfcc = pad2d(mfcc, 400)\n",
    "        \n",
    "        # Scream Dataset 에 추가\n",
    "        train_dataset.append((padded_mfcc, 0))\n",
    "    except Exception as e:\n",
    "        print(filename, e)\n",
    "        raise\n",
    "\n",
    "# train data non_scream 을 넣는다.\n",
    "for filename in os.listdir(DATA_DIR_TRAIN + \"non_scream/\"):\n",
    "    filename = normalize('NFC', filename)\n",
    "    try:\n",
    "        if '.wav' not in filename:\n",
    "            continue\n",
    "        \n",
    "        wav, sr = librosa.load(DATA_DIR_TRAIN + \"non_scream/\" + filename, sr=16000)\n",
    "        \n",
    "        mfcc = librosa.feature.mfcc(y=wav, sr=sr)\n",
    "        #mfcc = sklearn.processing.scale(mfcc, axis=1)\n",
    "        padded_mfcc = pad2d(mfcc, 400)\n",
    "        \n",
    "        # non_scream Dataset 에 추가\n",
    "        train_dataset.append((padded_mfcc, 1))\n",
    "    except Exception as e:\n",
    "        print(filename, e)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c984ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data scream 을 넣는다.\n",
    "for filename in os.listdir(DATA_DIR_TEST + \"test_scream/\"):\n",
    "    filename = normalize('NFC', filename)\n",
    "    try:\n",
    "        if '.wav' not in filename:\n",
    "            continue\n",
    "        \n",
    "        wav, sr = librosa.load(DATA_DIR_TEST + \"test_scream/\" + filename, sr=16000)\n",
    "        \n",
    "        input_nfft = int(round(sr*frame_length))\n",
    "        input_stride = int(round(sr*frame_stride))\n",
    "        \n",
    "        mfcc = librosa.feature.mfcc(y=wav, sr=sr)\n",
    "        #mfcc = sklearn.preprocessing.scale(mfcc, axis=1)\n",
    "        padded_mfcc = pad2d(mfcc, 400)\n",
    "        \n",
    "        \n",
    "        # test scream dataset 에 추가\n",
    "        test_dataset.append((padded_mfcc, 0))\n",
    "    except Exception as e:\n",
    "        print(filename, e)\n",
    "        raise\n",
    "\n",
    "# test data non_scream 을 넣는다.\n",
    "for filename in os.listdir(DATA_DIR_TEST + \"test_non_scream/\"):\n",
    "    filename = normalize('NFC', filename)\n",
    "    try:\n",
    "        if '.wav' not in filename:\n",
    "            continue\n",
    "        \n",
    "        wav, sr = librosa.load(DATA_DIR_TEST + \"test_non_scream/\" + filename, sr=16000)\n",
    "        \n",
    "        input_nfft = int(round(sr*frame_length))\n",
    "        input_stride = int(round(sr*frame_stride))\n",
    "        \n",
    "        mfcc = librosa.feature.mfcc(y=wav, sr=sr)\n",
    "        #mfcc = sklearn.preprocessing.scale(mfcc, axis=1)\n",
    "        padded_mfcc = pad2d(mfcc, 400)\n",
    "        \n",
    "        # test non_scream dataset 에 추가\n",
    "        test_dataset.append((padded_mfcc, 1))\n",
    "    except Exception as e:\n",
    "        print(filename, e)\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "482f6516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_mfccs :  (3069, 20, 400)\n",
      "train_y :  (3069, 2)\n",
      "test_mfccs :  (486, 20, 400)\n",
      "test_y :  (486, 2)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 셋 셔플\n",
    "random.shuffle(test_dataset)\n",
    "random.shuffle(train_dataset)\n",
    "\n",
    "train_mfccs = [a for (a,b) in train_dataset]\n",
    "train_y = [b for (a,b) in train_dataset]\n",
    "\n",
    "test_mfccs = [a for (a,b) in test_dataset]\n",
    "test_y = [b for (a,b) in test_dataset]\n",
    "\n",
    "train_mfccs = np.array(train_mfccs)\n",
    "train_y = to_categorical(np.array(train_y))\n",
    "\n",
    "test_mfccs = np.array(test_mfccs)\n",
    "test_y = to_categorical(np.array(test_y))\n",
    "\n",
    "print('train_mfccs : ', train_mfccs.shape)\n",
    "print('train_y : ', train_y.shape)\n",
    "\n",
    "print('test_mfccs : ', test_mfccs.shape)\n",
    "print('test_y : ', test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141a30c1",
   "metadata": {},
   "source": [
    "# MFCC feature 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62327bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape :  (3069, 20, 400, 1)\n",
      "test X shape :  (486, 20, 400, 1)\n"
     ]
    }
   ],
   "source": [
    "train_X_ex = np.expand_dims(train_mfccs, -1)\n",
    "test_X_ex = np.expand_dims(test_mfccs, -1)\n",
    "print('train X shape : ', train_X_ex.shape)\n",
    "print('test X shape : ', test_X_ex.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e748d854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 20, 400, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 17, 397, 96)       1632      \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 4, 99, 96)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 38016)             0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 32)                1216544   \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 32)                0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,218,242\n",
      "Trainable params: 1,218,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ip = Input(shape=train_X_ex[0].shape)\n",
    "\n",
    "m = Conv2D(32, kernel_size=(4,4), activation='relu')(ip)\n",
    "#m = BatchNormalization()(m)\n",
    "m = MaxPooling2D(pool_size=(4,4))(m)\n",
    "\n",
    "m = Conv2D(32*2, kernel_size=(4,4), activation='relu')(ip)\n",
    "#m = BatchNormalization()(m)\n",
    "m = MaxPooling2D(pool_size=(4,4))(m)\n",
    "\n",
    "m = Conv2D(32*3, kernel_size=(4,4), activation='relu')(ip)\n",
    "#m = BatchNormalization()(m)\n",
    "m = MaxPooling2D(pool_size=(4,4))(m)\n",
    "\n",
    "m = Flatten()(m)\n",
    "\n",
    "m = Dense(32)(m)\n",
    "#m = BatchNormalization()(m)\n",
    "m = Activation(\"relu\")(m)\n",
    "\n",
    "op = Dense(2, activation='softmax')(m)\n",
    "\n",
    "model = Model(ip, op)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7db13a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "96/96 [==============================] - 5s 44ms/step - loss: 1.0570 - accuracy: 0.8530 - val_loss: 0.3108 - val_accuracy: 0.9362\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 4s 42ms/step - loss: 0.2254 - accuracy: 0.9303 - val_loss: 0.1367 - val_accuracy: 0.9671\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 4s 42ms/step - loss: 0.1595 - accuracy: 0.9391 - val_loss: 0.1330 - val_accuracy: 0.9733\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 4s 42ms/step - loss: 0.1478 - accuracy: 0.9475 - val_loss: 0.1760 - val_accuracy: 0.9753\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 4s 43ms/step - loss: 0.1223 - accuracy: 0.9498 - val_loss: 0.1118 - val_accuracy: 0.9712\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 4s 43ms/step - loss: 0.1286 - accuracy: 0.9479 - val_loss: 0.1121 - val_accuracy: 0.9712\n",
      "Epoch 7/100\n",
      "49/96 [==============>...............] - ETA: 1s - loss: 0.1117 - accuracy: 0.9509"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 만약 3개 이상의 클래스 분류를 해야한다면 categorical_crossentropy 를 사용\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m               optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X_ex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_X_ex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 만약 3개 이상의 클래스 분류를 해야한다면 categorical_crossentropy 를 사용\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_X_ex,\n",
    "                    train_y,\n",
    "                    epochs=100,\n",
    "                    batch_size=32,\n",
    "                    verbose=1,\n",
    "                    validation_data=(test_X_ex, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fce9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a95285",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_length = 160\n",
    "n_fft = 400\n",
    "\n",
    "file_path_ = \"/content/drive/MyDrive/Data\"\n",
    "\n",
    "audio_data = []\n",
    "for root, dirs, files in os.walk(file_path_):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            y, sr = librosa.load(file_path, sr=None)\n",
    "            audio_data.append((file_path, y, sr))\n",
    "\n",
    "print(\"읽은 오디오 파일 수:\", len(audio_data))\n",
    "\n",
    "for file_path, signal, sample_rate in audio_data:\n",
    "    signal, sample_rate = librosa.load(file_path, sr=16000)\n",
    "    MFCCs = librosa.feature.mfcc(y=signal, sr=sample_rate, n_fft=n_fft, hop_length=hop_length, n_mfcc=100)\n",
    "    MFCCs = sklearn.preprocessing.scale(MFCCs, axis=1)\n",
    "    pad2d = lambda a, i: a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i-a.shape[1]))))\n",
    "    padded_mfcc = pad2d(MFCCs, 400)\n",
    "\n",
    "print(\"MFCCs shape : \", MFCCs.shape)\n",
    "print(\"pad shape : \", padded_mfcc.shape)\n",
    "librosa.display.specshow(padded_mfcc, sr=16000, x_axis='time')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
